{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eaf76b63",
   "metadata": {},
   "source": [
    "![logo](../img/LogoLine_horizon_C3S.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95a990b",
   "metadata": {},
   "source": [
    "# How to access and use a satellite-derived GHG Level 2 data product using XCO2_EMMA as an example? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ae6850",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "This is a Jupyter Notebook (JN) illustrating how to access and use a satellite-derived Greenhouse Gas (GHG) atmospheric carbon dioxide (CO2) Level 2 data product as generated via the Copernicus Climate Change Service (C3S) and made available via the Copernicus Climate Data Store [CDS](https://cds.climate.copernicus.eu/).\n",
    "\n",
    "Here we illustrate the use of a GHG Level 2 (L2) product using product XCO2_EMMA as an example. A CO2 L2 data product contains CO2 information for individual satellite ground pixels (also called footprints or soundings). XCO2 is the column-averaged dry-air mole fraction of atmospheric CO2 in parts per million (ppm). EMMA is the name of the multi-satellite XCO2 (and XCH4) merging algorithm developed to generate product XCO2_EMMA using as input individual Level 2 XCO2 products from different satellite sensors (here: SCIAMACHY/ENVISAT, GOSAT, GOSAT-2 and OCO-2; see, e.g., [Reuter et al., 2020](https://amt.copernicus.org/articles/13/789/2020/)). \n",
    "\n",
    "Within C3S also other L2 products are generated and made available via the CDS. These products are (i) XCO2 from individual satellite sensors, (ii) XCH4 products, where XCH4 is the column-averaged dry-air mole fraction of CH4 in parts per billion (ppb), and (iii) mid tropospheric CO2 and CH4 mixing ratio products. Detailed information on all these products is available via the CDS. In addition to L2 products, also Level 3 (L3) products are available. A L3 product is based on a corresponding L2 product. A L3 product is  obtained by spatio-temporally averaging a corresponding L2 product. How to access and use a L3 GHG product is shown in a separate Jupyter Notebook.\n",
    "\n",
    "For this JN we use XCO2_EMMA version 4.4, which covers the period 2003 - 2021. \n",
    "\n",
    "This JN shows how to download a data product from the CDS, explains how to access the main variables and how to use them for a given applications. We focus on two use cases related to the spatial and temporal variation of atmospheric CO2 concentrations and their observational coverage. \n",
    "\n",
    "The first use case is related to the latitudial distribution of XCO2. We show how XCO2 averages and standard devations per latitude band can be computed and plotted. For this we use two days of observations, one in April and one in September. We explain that the observed latitudinal distributions are closely related to the seasonal cycle of CO2 due to uptake and release of CO2 by vegetation.\n",
    "\n",
    "For the second use case we show how a map of the spatial distribution of the individual ground pixel XCO2 observations can be generated. We show that the spatial coverage of the daily observations is very sparse due to strict quality filtering of the individual XCO2 retrievals. Most applications therefore require appropriate spatio-temporal averaging (see, for example, the use of C3S GHG XCO2 and XCH4 data for assessments such as Copernicus European State of the Climate (ESOTC) as shown on the [GHG concentration climate indicators website]( https://climate.copernicus.eu/climate-indicators/greenhouse-gas-concentrations)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8127383e",
   "metadata": {},
   "source": [
    "### What is needed to use this Jupyter Notebook?\n",
    "\n",
    "In the following, Python 3 code is provided to read and plot the satellite data.\n",
    "\n",
    "It is assumed that Python and Jupyter Notebook (JN) is installed on your computer, e.g., using the [Anaconda distribution](https://www.anaconda.com/products/distribution).\n",
    "\n",
    "### Import libraries used in this tutorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13856795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import os\n",
    "# from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0dc7688",
   "metadata": {},
   "source": [
    "## Data download from CDS\n",
    "\n",
    "C3S GHG data products can be obtained from the CDS via the CDS user interface, or via the cdsapi as is demonstrated in this tutorial. \n",
    "\n",
    "The satellite-derived CO2 products, and documentation are available here: \n",
    "https://cds.climate.copernicus.eu/datasets/satellite-carbon-dioxide\n",
    "\n",
    "Product XCO2_EMMA can be downloaded by manual selection in the \"Download data\" tab. Please select:\n",
    "- Processing level: Level 2\n",
    "- Variable: Column-average dry-air mole fraction of atmospheric Carbon Dioxide (XCO2) and related variables\n",
    "- Sensor and algorithm: MERGED and EMMA\n",
    "\n",
    "For the following we assume that data for 2 days have been downloaded:\n",
    "- File 1: 15-April-2020\n",
    "- File 2: 15-September-2020\n",
    "\n",
    "It is also assumed that the following version and format of the data is selected:\n",
    "- Version: 4.4 \n",
    "- Format: Zip file \n",
    "\n",
    "The corresponding file names are:\n",
    "- File 1: 20200415-C3S-L2_GHG-GHG_PRODUCTS-MERGED-MERGED-EMMA-DAILY-v4.4.nc\n",
    "- File 2: 20200915-C3S-L2_GHG-GHG_PRODUCTS-MERGED-MERGED-EMMA-DAILY-v4.4.nc\n",
    "\n",
    "The following code block will download these data files and extract them to the current directory ready for use in this tutorial. This assumes that you have installed the cdsapi and configured you .cdsapirc file with your key, as described in the \"Climate Data Store Tutorial\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58023d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://cds-beta.climate.copernicus.eu/api'\n",
    "KEY = '#################'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626e329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_zip_file = \"download.zip\"\n",
    "dataset = \"satellite-carbon-dioxide\"\n",
    "request = {\n",
    "    'processing_level': ['level_2'],\n",
    "    'variable': 'xco2',\n",
    "    'sensor_and_algorithm': 'merged_emma',\n",
    "    'year': ['2020'],\n",
    "    'month': ['04', '09'],\n",
    "    'day': ['15'],\n",
    "    'version': ['4_4'],\n",
    "    \"format\": \"zip\",\n",
    "}\n",
    "\n",
    "client = cdsapi.Client(url=URL,key=KEY)\n",
    "client.retrieve(dataset, request).download(download_zip_file)\n",
    "\n",
    "with zipfile.ZipFile(download_zip_file) as zf:\n",
    "    zf.extractall()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12efe46",
   "metadata": {},
   "source": [
    "### Set some options that are used in this tutorial\n",
    "\n",
    "Here some information on the selected product (which will be used later for the plots):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19e093ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_id = 'XCO2_EMMA' \n",
    "product_version = '4.4'  \n",
    "product_str = product_id+' (v'+product_version+')'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "145204e2",
   "metadata": {},
   "source": [
    "Here some information on the selected days and corresponding file names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7776a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For file 1:\n",
    "year_1_str = '2020'; month_1_str = '04'; month_name_1_str = 'Apr'; day_1_str = '15'\n",
    "L2_file_1 = '20200415-C3S-L2_GHG-GHG_PRODUCTS-MERGED-MERGED-EMMA-DAILY-v4.4.nc'\n",
    "file_1_date = year_1_str+month_1_str+day_1_str\n",
    "file_1_date2 = day_1_str+'-'+month_name_1_str+'-'+year_1_str\n",
    "if os.path.exists(L2_file_1):\n",
    "   print(f'File 1 exists: {L2_file_1}')\n",
    "else:\n",
    "   print('File 1 not found, please data downloaded and extracted correctly')\n",
    "\n",
    "# For file 2:\n",
    "year_2_str = '2020'; month_2_str = '09'; month_name_2_str = 'Sep'; day_2_str = '15'\n",
    "L2_file_2 = '20200915-C3S-L2_GHG-GHG_PRODUCTS-MERGED-MERGED-EMMA-DAILY-v4.4.nc'\n",
    "file_2_date = year_2_str+month_2_str+day_2_str\n",
    "file_2_date2 = day_2_str+'-'+month_name_2_str+'-'+year_2_str\n",
    "if os.path.exists(L2_file_2):\n",
    "   print(f'File 2 exists: {L2_file_2}')\n",
    "else:\n",
    "   print('File 2 not found, please data downloaded and extracted correctly')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5bbe07",
   "metadata": {},
   "source": [
    "## Open data files with xarray\n",
    "\n",
    "We open the first file with xarray, and then set some of the variables to be coordinates (`latitude`, `longitude` and `time`).\n",
    "\n",
    "The print out of the `xarray.Dataset` allows you to explore the contents of the file. For this tutorial we will be using the `xco2` variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38ac8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1 = xr.open_dataset(L2_file_1)\n",
    "\n",
    "ds_1 = ds_1.assign_coords({\n",
    "   \"latitude\": ds_1.latitude,\n",
    "   \"longitude\": ds_1.longitude,\n",
    "   \"time\": ds_1.time,\n",
    "})\n",
    "\n",
    "ds_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a290246",
   "metadata": {},
   "source": [
    "Then repeat for file 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd9f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_2 = xr.open_dataset(L2_file_2)\n",
    "\n",
    "ds_2 = ds_2.assign_coords({\n",
    "   \"latitude\": ds_2.latitude,\n",
    "   \"longitude\": ds_2.longitude,\n",
    "   \"time\": ds_2.time,\n",
    "})\n",
    "\n",
    "ds_2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad79dcf6",
   "metadata": {},
   "source": [
    "## Application 1: The latitudinal distribution of XCO2\n",
    "\n",
    "Here our intention is to plot the data as a function of latitude. For this we first need to define the latitude bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('* Computing latitude band center coordinates')\n",
    "lat_band_width = 10.0  # Width of latitude band in deg\n",
    "d_lat = lat_band_width*0.5\n",
    "lat_band_min = -90.0 + d_lat\n",
    "lat_band_max = 90.0 - d_lat\n",
    "lat_band_bins = np.arange(-90, 91, lat_band_width)\n",
    "n_lat_bands = int((lat_band_max - lat_band_min) / lat_band_width)+1\n",
    "lat_band_center = np.zeros(n_lat_bands)\n",
    "for ii in range(n_lat_bands):\n",
    "   lat_band_center[ii] = lat_band_min + ii*lat_band_width\n",
    "print('* lat_band_center: ', lat_band_center)\n",
    "print('* lat_band_bins: ', lat_band_bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49cd8b4",
   "metadata": {},
   "source": [
    "### Computing XCO2 vs latitude\n",
    "\n",
    "Now we compute the mean and standard deviation for each latitude band of XCO2 from files 1 and 2. As  we need to repeat this process for the data in file 1 and file 2, we will write a function to reduce the repetitive code.\n",
    "\n",
    "(Note: we identify \"No data\" via a negative standard deviation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f27be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonal_mean_and_std(dataset, lat_band_bins, lat_band_centres, variable=\"xco2\"):\n",
    "    # Group the data by latitude bands\n",
    "    grouped = dataset[variable].groupby_bins('latitude', lat_band_bins)\n",
    "\n",
    "    # Compute the zonal mean and standard deviation,\n",
    "    # assign the latitude centres as coordinates, and use this as the dimension\n",
    "    zonal_mean = grouped.mean()\n",
    "    zonal_mean = zonal_mean.assign_coords(latitude=(\"latitude_bins\", lat_band_center))\n",
    "    zonal_mean = zonal_mean.swap_dims({'latitude_bins': 'latitude'})\n",
    "\n",
    "    zonal_std = grouped.std()\n",
    "    zonal_std = zonal_std.assign_coords(latitude=(\"latitude_bins\", lat_band_center))\n",
    "    zonal_std = zonal_std.swap_dims({'latitude_bins': 'latitude'})\n",
    "\n",
    "    # finally, we mask the data where the standard deviation is zero\n",
    "    zonal_mean = zonal_mean.where(zonal_std > 0)\n",
    "    zonal_std = zonal_std.where(zonal_std > 0)\n",
    "\n",
    "    return zonal_mean, zonal_std"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e3a17b",
   "metadata": {},
   "source": [
    "Now calculate the mean and standard deviation using our function. We also caculate the mean+standard deviation and mean-standard deviation which will be used in the plot created below.\n",
    "\n",
    "The print out of the xarray object shows that we have xco2 data in a DataArray with a single dimension, `latitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c6fe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean and standard deviation of the Dataset for each latitude band\n",
    "xco2_lb_mean_1, xco2_lb_std_1 = zonal_mean_and_std(ds_1, lat_band_bins, lat_band_center)\n",
    "xco2_lb_low_1 = xco2_lb_mean_1 - xco2_lb_std_1\n",
    "xco2_lb_high_1 = xco2_lb_mean_1 + xco2_lb_std_1\n",
    "\n",
    "xco2_lb_mean_2, xco2_lb_std_2 = zonal_mean_and_std(ds_2, lat_band_bins, lat_band_center)\n",
    "xco2_lb_low_2 = xco2_lb_mean_2 - xco2_lb_std_2\n",
    "xco2_lb_high_2 = xco2_lb_mean_2 + xco2_lb_std_2\n",
    "\n",
    "xco2_lb_mean_1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d908404",
   "metadata": {},
   "source": [
    "### Generation of xy plot showing XCO2 vs latitude\n",
    "\n",
    "We can now plot this data using `matplotlib.pyplot`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41a7ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('* Generating XCO2 vs latitude plot ...')\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=[8, 6])\n",
    "xmin = 404.0\n",
    "xmax = 420.0\n",
    "ymin = -60.0\n",
    "ymax =  80.0\n",
    "\n",
    "#  Plot the data and the ranges:\n",
    "ax.plot(\n",
    "    xco2_lb_mean_1, xco2_lb_mean_1.latitude,\n",
    "    linewidth=6.0, color='red', zorder=39, label='Mean+/-Stddev '+file_1_date2\n",
    ")\n",
    "ax.plot(\n",
    "    [xco2_lb_low_1, xco2_lb_high_1],\n",
    "    [xco2_lb_mean_1.latitude, xco2_lb_mean_1.latitude],\n",
    "    linewidth=20.0, color='red', zorder=38, alpha=0.3\n",
    ")\n",
    "\n",
    "ax.plot(\n",
    "    xco2_lb_mean_2, xco2_lb_mean_2.latitude,\n",
    "    linewidth=6.0, color='black', zorder=39, label='Mean+/-Stddev '+file_1_date2\n",
    ")\n",
    "ax.plot(\n",
    "    [xco2_lb_low_2, xco2_lb_high_2],\n",
    "    [xco2_lb_mean_2.latitude, xco2_lb_mean_2.latitude],\n",
    "    linewidth=20.0, color='black', zorder=38, alpha=0.3\n",
    ")\n",
    "\n",
    "# Decorate the plot with some labels:\n",
    "title = product_str\n",
    "x_label = 'XCO$_2$ [ppm]'\n",
    "y_label = 'Latitude [deg]'\n",
    "plot_title = product_str+': XCO$_2$ vs latitude'\n",
    "ax.set_title(plot_title, fontsize=20)\n",
    "ax.set_xlabel(x_label, fontsize=16)\n",
    "ax.set_ylabel(y_label, fontsize=16)\n",
    "ax.set_xbound([xmin, xmax])\n",
    "ax.set_ybound([ymin, ymax])\n",
    "ax.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c81630",
   "metadata": {},
   "source": [
    "The figure above shows mean value of XCO2 as a function of latitude (thick lines) and the corresponding variation (computed as standard deviation of the individual XCO2 retrievals) within each latitude band (semi-transparent horizontal bars) for 15-April-2020 (red) and 15-September-2020 (black). As can be seen, during September XCO2 shows quite little variation with latitude, whereas in April XCO2 is significantly higher over the northern hemisphere (NH) compared to the southern hemisphere (SH). This is due to the seasonal cycle of CO2 primarily resulting from regular uptake and release of atmospheric CO2 by growing and decaying vegetation (photosythesis and respiration). Vegetation uptake reduces the CO2 concentration over the NH during the growing season (spring and summer) compared to the dormant season (winter). Over the SH there is less vegetation and therefore CO2 is relatively constant (apart from the general increase due to CO2 emissions by burning fossil fuels). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ec7085",
   "metadata": {},
   "source": [
    "## Application 2: Showing daily data on a map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e553bbf0",
   "metadata": {},
   "source": [
    "Here we show how to generate a plot showing the spatial distribution of the data. As can be seen, we use only three variables: XCO2, latitude and longitude. We define a small region in terms of latitude and longitude corner coordinates and select only data in this region for the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1714f99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('* Generating XCO2 map ...')\n",
    "# # Relevant input data:\n",
    "plot_title = product_str+' - '+file_2_date2\n",
    "# Define spatial region of interest:\n",
    "lonmin = -12.0\n",
    "lonmax =  35.0\n",
    "latmin =  32.0\n",
    "latmax =  65.0\n",
    "\n",
    "# Mask the data to the region of interest:\n",
    "ds = ds_2\n",
    "ds = ds.where(\n",
    "    (latmin<ds.latitude) & (ds.latitude <latmax) &\n",
    "    (lonmin<ds.longitude) & (ds.longitude <lonmax)\n",
    ")\n",
    "# Get the min and max values for the colorbar:\n",
    "rmin=ds.xco2.min()\n",
    "rmax=ds.xco2.max()\n",
    "\n",
    "# Create a figure with a geographic projection:\n",
    "projection = ccrs.PlateCarree()\n",
    "figsize = (9,7)\n",
    "fig = plt.figure(figsize=figsize)\n",
    "ax = fig.add_subplot(1,1,1, projection=projection)\n",
    "ax.set_extent([lonmin, lonmax, latmin, latmax], crs=projection)\n",
    "ax.add_feature(cfeature.OCEAN, color='powderblue')\n",
    "ax.add_feature(cfeature.COASTLINE)\n",
    "ax.add_feature(cfeature.BORDERS, alpha=0.5)\n",
    "gl = ax.gridlines(crs=projection, draw_labels=True, linewidth=1, color='gray', alpha=0.2)\n",
    "gl.top_labels  = False\n",
    "\n",
    "plt.scatter(\n",
    "    x=ds.longitude, y=ds.latitude, c=ds.xco2, s=20, zorder=10, alpha=0.8, cmap='viridis',\n",
    "    vmin=rmin, vmax=rmax\n",
    ")\n",
    "plt.colorbar(label='XCO$_2$ [ppm]', location='bottom', extend='both', shrink=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252d5040",
   "metadata": {},
   "source": [
    "The figure above shows the locations of the individual ground pixel observations and their corresponding XCO2 value using all \"good\" retrievals over Europe and surrounding area for 15-Sept-2020. As can be seen, the spatial coverage of the daily data is very sparse. This is because only data of the highest quality are contained in the product file. Strict quality filtering is important to meet the demanding requirements on accuracy and precision for satellite XCO2 data observations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TM-TESTING",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
