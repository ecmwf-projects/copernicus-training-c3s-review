{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](../img/LogoLine_horizon_C3S.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monthly mean tropospheric humidity data from satellite-based Radio Occultation measurements\n",
    "\n",
    "### About\n",
    "\n",
    "In this tutorial we will work with monthly-mean tropospheric humidity data from the Climate Data Store (CDS), demonstrating how the data can be accessed, and inspecting the data to get a quick view on the physical variables available and the data structures used. We will also have a closer look at some **_use cases_** that demonstrate a few useful applications and processing steps. The use cases include some plotting that will learn you about the humidity data and how it can be visualized.\n",
    "\n",
    "The tutorial includes the following:\n",
    "\n",
    "1. Background\n",
    "2. Initial setup\n",
    "3. Search, download, and inspect data\n",
    "4. Work with data\\\n",
    "  4.1 Use case 1: Global latitude-height distribution of tropospheric humidity\\\n",
    "  4.2 Use case 2: Climate normal and anomalies\\\n",
    "  4.3 Use case 3: Seasonal variations of tropospheric humidity\\\n",
    "  4.4 Use case 4: Global humidity and the El Niño Southern Oscillation\n",
    "5. References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Background\n",
    "\n",
    "Atmospheric humidity plays an important role in the Earth's climate system, both for its strong greenhouse effect but also for its role in the global energy transport. It is central to the hydrological cycle and sets the fundamental conditions for the biosphere, including distribution of rainfall and droughts.\n",
    "\n",
    "The gridded monthly-mean tropospheric humidity dataset, derived from a large number of observed humidity profiles retrieved from satellite-based Radio Occultation (RO) measurements, originate from EUMETSAT's ROM SAF facility. It comprises time series of continuous humidity observations from space, starting in late 2006 and regularly extended up to present. As the dataset encompasses the entire globe, from the surface up to an altitude of 12 kilometers, and have high vertical resolution revealing fine scale details of the variations with height, it is well suited for analysis of the latitudinal and height distributions of humidity. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial setup\n",
    "\n",
    "This tutorial assumes that the CDS API for Python has been installed, and that valid credentials have been acquired. The latter consist of a personal User ID and a CDS API key. In addition, a set of common Python packages must be installed.\n",
    "\n",
    "#### Install CDS API\n",
    "\n",
    "To install the CDS API, run the following command. We use an exclamation mark to pass the command to the shell (not to the Python interpreter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install cdsapi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import libraries\n",
    "\n",
    "We will work with data stored in multidimensional arrays, with associated meta-data propagated from the data files. For this purpose, we use a few standard Python libraries, in particular `Xarray` but also `Numpy`. We will also need libraries for file handling and plotting. For the latter, we will use `Matplotlib` as well as the `Xarray` built-in plotting tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CDS API\n",
    "import cdsapi\n",
    "\n",
    "# OS functions\n",
    "import os\n",
    "\n",
    "# File download and zip archive handling\n",
    "from urllib.request import urlretrieve\n",
    "import zipfile\n",
    "\n",
    "# Libraries for working with multidimensional arrays and time series data\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import cftime\n",
    "\n",
    "# Libraries for plotting and visualising data\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correct handling of time coordinates in Xarray datasets created from netCDF files may require a recent version of the package `nc-time-axis`, which can be installed with the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nc-time-axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Enter your CDS API key\n",
    "\n",
    "We will request data from the Climate Data Store (CDS) using functions in the CDS API. For that, you need to specify your CDS API credentials in the form of two strings:`URL` and `KEY`. The KEY string includes your personal User ID and a CDS API key. To obtain these, first register or login to the CDS (http://cds.climate.copernicus.eu), then visit https://cds.climate.copernicus.eu/api-how-to and copy the string of characters listed after \"key:\". Replace the `#########` below with this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://cds.climate.copernicus.eu/api/v2'\n",
    "KEY = '##################################'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Search, download, and inspect data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Identify the data in the Climate Data Store\n",
    "\n",
    "The data to use in this tutorial is the [Tropospheric humidity profiles averaged monthly and zonally from 2006 to present derived from satellite observations](https://cds.climate.copernicus.eu/cdsapp#!/dataset/satellite-humidity-profiles?tab=overview). Look up this dataset in the CDS and select the \"Download data\" tab. There, you will find a form where you can specify whether to use observed RO data or the corresponding reanalysis data, as well as the time period to study. Select the following parameters:\n",
    "\n",
    "    Product type: Radio occultation data\n",
    "    Year: All\n",
    "    Month: All\n",
    "    Variable: All available variables\n",
    "    Format: Zip file\n",
    "\n",
    "At the end of the download form, select \"Show API request\". A block of code will appear, which you can simply copy and paste into a cell of your Jupyter Notebook (see two cells below).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Download the data\n",
    "\n",
    "Specify a local directory for download of data from the CDS, and for storing all output files that will be generated. Note that the directory must exist.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = './data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the data to your local directory using CDS API functions (here you may use a block of code copied from the CDS download form instead of the code provided below).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = cdsapi.Client(url=URL, key=KEY)\n",
    "\n",
    "# Name of the zip file where data from the CDS land.\n",
    "zipfilepath = os.path.join(DATADIR, 'ro_hum_monthly_lhgrid.zip')\n",
    "\n",
    "# Download\n",
    "c.retrieve(\n",
    "    'satellite-humidity-profiles',\n",
    "    {\n",
    "        'product_type': 'radio_occultation_data',\n",
    "        'year': [\n",
    "            '2007', '2008', '2009',\n",
    "            '2010', '2011', '2012',\n",
    "            '2013', '2014', '2015',\n",
    "            '2016', '2017', '2018',\n",
    "            '2019', '2020', '2021',\n",
    "            '2022', '2023',\n",
    "        ],\n",
    "        'month': [\n",
    "            '01', '02', '03',\n",
    "            '04', '05', '06',\n",
    "            '07', '08', '09',\n",
    "            '10', '11', '12',\n",
    "        ],\n",
    "        'variable': 'all',\n",
    "        'format': 'zip',\n",
    "    },\n",
    "    zipfilepath\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Unpack and merge data files\n",
    "\n",
    "A zip file should now be available in your local directory. That file will now be unzipped into monthly netCDF files, which will then be merged into a single netCDF file containing all months. After that, the monthly files are deleted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip the data into monthly files (about 200 for the full RO dataset).\n",
    "with zipfile.ZipFile(zipfilepath, 'r') as zip_ref:\n",
    "    filelist = [os.path.join(DATADIR, f) for f in zip_ref.namelist()]\n",
    "    zip_ref.extractall(DATADIR)\n",
    "\n",
    "# Make sure the filelist is in the correct order.\n",
    "filelist.sort(key=lambda x: x.split('_')[3])\n",
    "\n",
    "# Merge monthly netCDF files into a single combined file.\n",
    "merged_netcdf_file = os.path.join(DATADIR, 'hum_mon_lagrid_metop.nc')\n",
    "ds = xr.open_mfdataset(filelist, concat_dim='time', combine='nested')\n",
    "ds.to_netcdf(merged_netcdf_file)\n",
    "\n",
    "# Delete the monthly netCDF files.\n",
    "for f in filelist:\n",
    "    os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Store as Xarray object and inspect data\n",
    "\n",
    "Now the data should be ready for inspection. The netCDF file format used here is commonly used for array-oriented scientific data. To read and process this data we will make use of the [Xarray](http://xarray.pydata.org/en/stable/) library. Xarray is a Python library designed for working with multi-dimensional arrays that include meta-data. We will read the data from the netCDF file into an [Xarray dataset](https://xarray.pydata.org/en/stable/generated/xarray.Dataset.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from the merged netCDF file into an Xarray dataset.\n",
    "ds = xr.open_dataset(merged_netcdf_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now inspect the Xarray dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset has one _data variable_ called **_Q_**, which is the monthly mean specific humidity, and four _coordinates_ **_time_**, **_alt_**, **_lat_**, and **_lon_**. The _dimensions_ show that the longitude is collapsed into a single grid point, while there are 36 latitudes and 251 altitudes. Hence, the grid is a purely zonal latitude-altitude grid, with data averaged over all longitudes.\n",
    "\n",
    "We now remove the longitude dimension since that is not really used. We also convert altitudes to kilometers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the longitude dimension, which has size one\n",
    "ds = ds.drop_vars(['lon', 'lon_bnd'])\n",
    "ds = ds.squeeze()\n",
    "\n",
    "# Convert altitudes to kilometer\n",
    "ds.coords['alt'] = ds['alt'] / 1000.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While an Xarray `Dataset` may contain multiple variables, an Xarray `DataArray` holds a single multi-dimensional variable and its coordinates. Let us now extract data arrays from the datasets, in order to simplify the data processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Xarray data arrays from Xarray datasets\n",
    "da_year  = ds['year']\n",
    "da_month = ds['month']\n",
    "da_mean  = ds['Q']\n",
    "da_stdev = ds['Q_stdev']\n",
    "da_num   = ds['Q_num']\n",
    "\n",
    "# Extract dimensions as integers\n",
    "Ntime = ds.dims['time']\n",
    "Nalt  = ds.dims['alt']\n",
    "Nlat  = ds.dims['lat']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now inspect the data array containing the humidity monthly means:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, we find that this Xarray object only contains the humidity monthly means, along with the relevant coordinate variables and attributes. \n",
    "\n",
    "In some of the use cases below, we will work with Numpy arrays instead of Xarray arrays. The conversion to Numpy arrays is straightforward using Xarray methods: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Xarray arrays to Numpy arrays. The Numpy method 'squeeze' removes dimensions of size one.\n",
    "np_year  = da_year.values\n",
    "np_month = da_month.values\n",
    "np_mean  = da_mean.values.squeeze()\n",
    "np_stdev = da_stdev.values.squeeze()\n",
    "np_num   = da_num.values.squeeze()\n",
    "np_lat   = da_mean.coords['lat'].values\n",
    "np_alt   = da_mean.coords['alt'].values\n",
    "\n",
    "# Extract start and end of time series as integers\n",
    "year0  = np_year[0]\n",
    "yearF  = np_year[Ntime-1]\n",
    "month0 = np_month[0]\n",
    "monthF = np_month[Ntime-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Work with data\n",
    "\n",
    "We will now present four use cases that demonstrate some useful applications and processing steps, and that will learn you about the humidity data and how it can be visualized. You can go directly to any of the first three use cases without having to execute the previous ones. However, Use case 4 requires that you first go through Use case 3. \n",
    "\n",
    "### 4.1 Use case 1: Global latitude-height distribution of tropospheric humidity\n",
    "\n",
    "#### 4.1.1 Monthly mean humidity\n",
    "\n",
    "This use case is about visualizing humidity data from a selected month. With the built-in Xarray method `plot()`, you can easily plot a certain time step of the loaded array. Let's generate some plots for January 2007."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# January 2007\n",
    "pltyear  = 2007\n",
    "pltmonth = 1\n",
    "\n",
    "itime = 12*(pltyear-year0) + pltmonth - month0\n",
    "\n",
    "monstrng = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "            'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "print('\\n Selected month: ', monstrng[da_month.data[itime]-1], da_year.data[itime])\n",
    "\n",
    "da_mean[itime, :, :].plot(xlim=[-90.0, 90.0], ylim=[0.0, 12.0], vmin=0.0, vmax=15.0,\n",
    "                          extend='max', cmap='coolwarm')  # 'RdBu_r', 'coolwarm'\n",
    "# Arguments controlling figure size and color map: figsize=(8,6), cmap='RdBu_r'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An alternative to the built-in Xarray plotting functions is to use [Matplotlib](https://matplotlib.org/) plotting tools that operate on Numpy arrays. Here, we repeat the monthly mean humidity plot using Matplotlib. The _contourf_ function gives a less \"noisy\" plot than _pcolormesh_, and have access to more plot options, but may require some experimentation. It is also possible to save the plot as a png file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the figure panel\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# Plot the data with pcolormesh\n",
    "# im = plt.pcolormesh(X, Y, Z[imon,:,:,0], vmin=0.0, vmax=15.0, cmap='coolwarm')   # 'RdBu_r'\n",
    "\n",
    "# ... or plot with contour/contourf, manually defining the set of contours\n",
    "clevels = [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0]\n",
    "im = plt.contour(np_lat, np_alt, np_mean[itime, :, :], levels=clevels, linewidths=0.4, colors='b')\n",
    "im = plt.contourf(np_lat, np_alt, np_mean[itime, :, :], levels=clevels, vmin=0.0, vmax=15.0,\n",
    "                  extend='max', cmap='coolwarm')   # 'RdBu_r', 'RdYlBu_r', 'BuRd'\n",
    "\n",
    "# Set figure title, axes ticks and labels, grid, etc.\n",
    "ax.set_title('Humidity', fontsize=16)\n",
    "ax.set_xlabel('latitude  /  deg N', fontsize=12)\n",
    "ax.set_ylabel('altitude  /  km', fontsize=12)\n",
    "ax.set_xlim(xmin=-90.0, xmax=90.0)\n",
    "ax.set_ylim(ymin=0.0, ymax=12.0)\n",
    "ax.xaxis.set_ticks([-90, -60, -30, 0, 30, 60, 90])\n",
    "ax.xaxis.grid(True, linewidth=0.4, linestyle='-', color='0.8')\n",
    "\n",
    "# Specify the colorbar\n",
    "cbar = fig.colorbar(im, fraction=0.05, pad=0.04)\n",
    "cbar.set_label('monthly mean humidity  /  g/kg')\n",
    "\n",
    "# Save the figure as a png file\n",
    "# fig.savefig(f'{DATADIR}hum_mon_lagrid_metop.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the humidity has a peak in the lower troposphere near the equator. As we will se below (Use case 3) this peak moves seasonally back and forth in the north-south direction, as the Inter-Tropical Convergence Zone (ITCZ) moves through the seasons. We will also see (Use case 4) that the ENSO phenomenon in the Pacific has a dominating impact on the global humidity.\n",
    "\n",
    "#### 4.1.2 Monthly standard deviation\n",
    "\n",
    "Similarly, we can plot the monthly standard deviation as measure of the variability of the humidity within a month:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the figure panel\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n",
    "\n",
    "# Plot the data with pcolormesh\n",
    "# im = plt.pcolormesh(X, Y, Z[imon,:,:,0], vmin=0.0, vmax=4.0, cmap='coolwarm')   # 'RdBu_r'\n",
    "\n",
    "# ... or plot with contour/contourf\n",
    "im = plt.contour(np_lat, np_alt, np_stdev[itime, :, :], levels=15, linewidths=0.4, colors='b')\n",
    "im = plt.contourf(np_lat, np_alt, np_stdev[itime, :, :], levels=15, vmin=0.0, vmax=4.0,\n",
    "                  extend='max', cmap='coolwarm')   # 'RdBu_r'\n",
    "\n",
    "# Set figure title, axes ticks and labels, grid, etc.\n",
    "ax.set_title('Humidity variability', fontsize=16)\n",
    "ax.set_xlabel('latitude  /  deg N', fontsize=12)\n",
    "ax.set_ylabel('altitude  /  km', fontsize=12)\n",
    "ax.set_xlim(xmin=-90.0, xmax=90.0)\n",
    "ax.set_ylim(ymin=0.0, ymax=12.0)\n",
    "ax.xaxis.set_ticks([-90, -60, -30, 0, 30, 60, 90])\n",
    "ax.xaxis.grid(True, linewidth=0.4, linestyle='-', color='0.8')\n",
    "\n",
    "# Specify the colorbar\n",
    "cbar = plt.colorbar(im, fraction=0.05, pad=0.04)\n",
    "cbar.set_label('monthly standard deviation of humidity  /  g/kg')\n",
    "\n",
    "# Save the figure\n",
    "# fig.savefig(f'{DATADIR}hum_mon_lagrid_metop.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The zonal standard deviation plot has a pronounced two-peaked structure. This is largely a consequence of the fact that the standard deviation in a zonal grid not only measures the variability in time, but also the variability in longitude. Near the edge of the ITCZ, between say 15-25 degrees latitude, we find regions that are dry as well as regions that are humid at the same latitude, while nearer the equator humid conditions prevail at almost all longitudes. Just like the humidity distribution, the variability distribution moves seasonally back and forth over the equator as the ITCZ moves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.2 Use case 2: Climate normal and anomalies\n",
    "\n",
    "#### 4.2.1 WMO standard reference periods\n",
    "\n",
    "The World Meteorological Organization (WMO) defines standard reference periods for which climate normals are computed. Since 2021, the WMO recommends basing climate normals on the 1991-2020 reference period, replacing the previously used time period 1981-2010. \n",
    "\n",
    "Climate normals can be considered as the typical climate for the period the normals are based on. It is important that the reference periods are long enough that year-to-year variations are reasonably averaged out in the computed normals.\n",
    "\n",
    "#### 4.2.2 Climate normals for a reference period\n",
    "\n",
    "Many observational data records are not available for the full 30-year reference period recommended by the WMO. We have to work with shorter reference periods, limited by the availability of data.\n",
    "\n",
    "To compute a climate normal we first define a certain reference period, and limit the data arrays to that period:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a reference time period. Whole years.\n",
    "year_ref_from = 2007\n",
    "year_ref_to   = 2022\n",
    "\n",
    "Ntime_ref = 12*(year_ref_to - year_ref_from + 1)\n",
    "\n",
    "# Select data from the reference period (for computing the normals)\n",
    "da_mean_ref = da_mean.where((da_year >= year_ref_from) & (da_year <= year_ref_to), drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then compute two types of normal: a) the long-term climatological mean and b) the mean annual cycle (i.e., the climatologies for the particular months). For the latter, we use the Xarray method `groupby()` to group the data by month."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normals: long-term mean and mean seasonal cycle over the reference period\n",
    "da_longnorm = da_mean_ref.mean(dim='time', skipna=True, keep_attrs=True)\n",
    "da_seasnorm = da_mean_ref.groupby('time.month').mean(skipna=True, keep_attrs=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the long-term climatological mean (using the built-in Xarray plot tool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_longnorm.plot(xlim=[-90.0, 90.0], ylim=[0.0, 12.0], vmin=0.0, vmax=15.0,\n",
    "                 extend='max', cmap='coolwarm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the 12 monthly climatological means, representing the mean annual cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "monstrng = ['January', 'February', 'March', 'April', 'May', 'June', 'July',\n",
    "            'August', 'September', 'October', 'November', 'December']\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(14, 12))\n",
    "\n",
    "for irow in range(4):\n",
    "    da_seasnorm.sel(month=3*irow+1).plot(\n",
    "        ax=axes[irow, 0], ylim=[0.0, 12.0], cmap=\"coolwarm\", add_colorbar=True, vmin=0.0, vmax=15.0,\n",
    "        extend=\"max\")\n",
    "\n",
    "    da_seasnorm.sel(month=3*irow+2).plot(\n",
    "        ax=axes[irow, 1], ylim=[0.0, 12.0], cmap=\"coolwarm\", add_colorbar=True, vmin=0.0, vmax=15.0,\n",
    "        extend=\"max\")\n",
    "\n",
    "    da_seasnorm.sel(month=3*irow+3).plot(\n",
    "        ax=axes[irow, 2], ylim=[0.0, 12.0], cmap=\"coolwarm\", add_colorbar=True, vmin=0.0, vmax=15.0,\n",
    "        extend=\"max\")\n",
    "\n",
    "    axes[irow, 0].set_title(monstrng[3*irow+0])\n",
    "    axes[irow, 1].set_title(monstrng[3*irow+1])\n",
    "    axes[irow, 2].set_title(monstrng[3*irow+2])\n",
    "\n",
    "    axes[irow, 0].set_ylabel(\"altitude  [km]\")\n",
    "    axes[irow, 1].set_ylabel(\"\")\n",
    "    axes[irow, 2].set_ylabel(\"\")\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axes.get_xaxis().set_ticklabels([])\n",
    "    ax.axes.get_yaxis().set_ticklabels([])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.suptitle(\"Humidity mean annual cycle\", fontsize=16, y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 4.2.3 Anomalies with respect to a normal\n",
    "\n",
    "With the normals thus defined, we can compute the anomalies with respect to the long-term climatological means as well as the anomalies with respect to the mean annual cycle. It is commonly the latter that is loosely referred to as \"anomalies\". Alternatively, we can express the anomalies in fractional terms, as the difference in percent relative to the normal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anomalies: relative to long-term mean and relative to mean seasonal cycle\n",
    "da_amean    = da_mean - da_longnorm\n",
    "da_desamean = da_mean.groupby('time.month') - da_seasnorm\n",
    "\n",
    "# Fractional anomalies\n",
    "da_famean    = 100.0 * (da_amean / da_longnorm)\n",
    "da_desfamean = 100.0 * (da_desamean.groupby('time.month') / da_seasnorm)\n",
    "\n",
    "\n",
    "# Alternative without using the Xarray grouping functionality\n",
    "\n",
    "# Initiate arrays\n",
    "# da_amean     = da_mean_ref.copy()\n",
    "# da_desamean  = da_mean_ref.copy()\n",
    "# da_famean    = da_mean_ref.copy()\n",
    "# da_desfamean = da_mean_ref.copy()\n",
    "\n",
    "# Anomalies: relative to long-term mean and relative to mean seasonal cycle\n",
    "# for itime in range(0,Ntime_ref):\n",
    "#   imon = int(da_month_ref[itime])\n",
    "#   da_amean[itime,:,:]    = da_mean_ref[itime,:,:] - da_longnorm[:,:]\n",
    "#   da_desamean[itime,:,:] = da_mean_ref[itime,:,:] - da_seasnorm[imon-1,:,:]\n",
    "\n",
    "# Fractional anomalies\n",
    "# for itime in range(0,Ntime_ref):\n",
    "#   imon = int(da_month_ref[itime])\n",
    "#   da_famean[itime,:,:]    = 100.0 * (da_amean[itime,:,:] / da_longnorm[:,:])\n",
    "#   da_desfamean[itime,:,:] = 100.0 * (da_desamean[itime,:,:] / da_seasnorm[imon-1,:,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last data array ('da_desfamean') contains the fractional anomalies with respect to the mean seasonal cycle, or 'deseasonalized' anomalies. Let us now plot these anomalies for a full year:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pltyear = 2007\n",
    "\n",
    "itime0 = 12*(pltyear - year_ref_from)\n",
    "\n",
    "fig, axes = plt.subplots(nrows=4, ncols=3, figsize=(14, 12))\n",
    "\n",
    "for irow in range(4):\n",
    "    for icol in range(3):\n",
    "        da_desfamean[itime0+3*irow+icol, :, :].plot(\n",
    "            ax=axes[irow, icol], ylim=[0.0, 12.0],\n",
    "            vmin=-30.0, vmax=30.0, cmap=\"coolwarm\",\n",
    "            add_colorbar=True, extend=\"both\", cbar_kwargs={'label': \"Humidity  [%]\"})\n",
    "        axes[irow, icol].set_title(monstrng[3*irow+icol])\n",
    "        axes[irow, icol].set_ylabel(\"altitude  [km]\")\n",
    "\n",
    "for icol in range(3):\n",
    "    axes[3, icol].set_xlabel(\"latitude  [deg N]\")\n",
    "\n",
    "for ax in axes.flat:\n",
    "    ax.axes.get_xaxis().set_ticklabels([])\n",
    "    ax.axes.get_yaxis().set_ticklabels([])\n",
    "    ax.set_xlabel(\"\")\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "fig.suptitle(\"Humidity anomalies during \"+str(pltyear), fontsize=16, x=0.48, y=1.02)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is emphasized that the percentages in the anomaly plots are the deviations of the specific humidity from the selected normal. It has nothing to do with relative humidity.\n",
    "\n",
    "We find that the anomalies are mostly within about 10-15% of the normal seasonal cycle, occasionally and regionally extending to 20-30% or more. Some years (e.g., 2008) are globally drier and some years (e.g., 2016) are more humid. An important factor for the global humidity is the equatorial Pacific with the El Niño Southern Oscillation (ENSO) cycles, which is further explored in Use case 4 below. \n",
    "\n",
    "You can change normal, from mean seasonal cycle to long-term climatology by using the variable 'da_famean' instead of 'da_desfamean'. You may also need to change the span of the colorbar from 30% to 100% to accommodate the larger deviations from the normal. Doing this for any year reveal the strong seasonal cycle of the specific humidity, where the change of sign of the anomaly in a hemisphere occurs in May and November. The seasonal variations of the humidity is further explored in Use case 3 below.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 4.3 Use case 3: Seasonal variations of tropospheric humidity\n",
    "\n",
    "We will now take a closer look at the seasonal humidity variations; first height-resolved and then vertically averaged over atmospheric layers.\n",
    "\n",
    "#### 4.3.1 Averaging humidity in latitude zones\n",
    "The data are already averaged over longitude and within 5-degree latitude bands. The averaging has been done at fixed altitudes. Let us now average in six larger latitude zones, including globally, but still keep the data height resolved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary defining the latitude zones\n",
    "latzones = {\n",
    "    '90°S-60°S': [0,  0,  6],  # [-90,-60],\n",
    "    '60°S-30°S': [1,  6, 12],  # [-60,-30],\n",
    "    '30°S-30°N': [2, 12, 24],  # [-30, 30],\n",
    "    '30°N-60°N': [3, 24, 30],  # [ 30, 60],\n",
    "    '60°N-90°N': [4, 30, 36],  # [ 60, 90],\n",
    "    '90°S-90°N': [5,  0, 36]}  # [-90, 90]}\n",
    "\n",
    "# Define a new data array to hold the latitude zone averages (Ntime x Nalt x Nlatzone)\n",
    "da_mean_latzone = da_mean[:, :, 0:6].copy().rename({'lat': 'latzone'})\n",
    "\n",
    "# Define a new data array to hold the cos-lat-weighted humidity data (Ntime x Nalt x Nlat)\n",
    "da_mean_weighted = da_mean.copy()\n",
    "\n",
    "# Compute averages in five latitude zones and globally\n",
    "latweight = np.cos(np.deg2rad(da_mean.lat[:])).rename('latweight')\n",
    "latweight = latweight.expand_dims(dim={\"time\": 194, \"alt\": 251})   # broadcast the latweight array\n",
    "latweight_masked = latweight.where(da_mean.notnull())   # weights are NaN where da_mean is NaN\n",
    "for izon in latzones:\n",
    "    i = latzones[izon][0]   # latzone\n",
    "    k = latzones[izon][1]   # from lat\n",
    "    n = latzones[izon][2]   # to lat\n",
    "    da_mean_weighted[:, :, k:n] = da_mean[:, :, k:n] * latweight_masked[:, :, k:n] / \\\n",
    "                                  latweight_masked[:, :, k:n].sum(dim='lat', skipna=True)\n",
    "    da_mean_latzone[:, :, i] = da_mean_weighted[:, :, k:n].mean(dim='lat', skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Xarray object 'da_mean_latzone' contains monthly mean humidity in six wide latitude zones instead of the 5-degree latitude bands. Following the example in Use case 2 above, we now compute the anomalies of that data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a reference time period. Whole years.\n",
    "year_ref_from = 2007\n",
    "year_ref_to   = 2022\n",
    "\n",
    "Ntime_ref = 12*(year_ref_to - year_ref_from + 1)\n",
    "\n",
    "# Select data from the reference period (for computing the normals)\n",
    "da_mean_latzone_ref = da_mean_latzone.where((da_year >= year_ref_from) &\n",
    "                                            (da_year <= year_ref_to), drop=True)\n",
    "\n",
    "# Normals: long-term mean and mean seasonal cycle over the reference period\n",
    "da_longnorm = da_mean_latzone_ref.mean(dim='time', skipna=True, keep_attrs=True)\n",
    "da_seasnorm = da_mean_latzone_ref.groupby('time.month').mean(skipna=True, keep_attrs=True)\n",
    "\n",
    "# Anomalies relative to a) long-term mean and b) mean seasonal cycle\n",
    "da_amean_latzone    = da_mean_latzone - da_longnorm\n",
    "da_desamean_latzone = da_mean_latzone.groupby('time.month') - da_seasnorm\n",
    "\n",
    "# Fractional anomalies\n",
    "da_famean_latzone    = 100.0 * (da_amean_latzone / da_longnorm)\n",
    "da_desfamean_latzone = 100.0 * (da_desamean_latzone.groupby('time.month') / da_seasnorm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### 4.3.2 Seasonal cycles in height-resolved data\n",
    "\n",
    "We can now plot the height-resolved anomalies as time series. Let us do this for the fractional anomalies (anomalies expressed in percent) in three latitude zones: northern mid-latitudes, low latitudes, and southern mid-latitudes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start/end times as instances of cftime\n",
    "date_from = cftime.datetime(year=np_year[0], month=np_month[0],  day=16)\n",
    "date_to   = cftime.datetime(year=np_year[Ntime-1], month=np_month[Ntime-1], day=16)\n",
    "\n",
    "# Northern mid-latitudes (30°N-60°N)\n",
    "izon = 3\n",
    "da_famean_latzone[:, :, izon].plot(figsize=(12, 4), x='time', y='alt',\n",
    "                                   xlim=[date_from, date_to], ylim=[0.0, 12.0],\n",
    "                                   vmin=-100.0, vmax=100.0, extend='max', cmap='RdBu_r',\n",
    "                                   cbar_kwargs={'label': \"Humidity anomaly  [%]\"})\n",
    "plt.title('Northern mid-latitudes: 30°N-60°N', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Altitude  [km]')\n",
    "plt.xlabel('')\n",
    "\n",
    "# Low latitudes (30°S-30°N)\n",
    "izon = 2\n",
    "da_famean_latzone[:, :, izon].plot(figsize=(12, 4), x='time', y='alt',\n",
    "                                   xlim=[date_from, date_to], ylim=[0.0, 12.0],\n",
    "                                   vmin=-100.0, vmax=100.0, extend='max', cmap='RdBu_r',\n",
    "                                   cbar_kwargs={'label': \"Humidity anomaly  [%]\"})\n",
    "plt.title('Low latitudes: 30°S-30°N', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Altitude  [km]')\n",
    "plt.xlabel('')\n",
    "\n",
    "# Southern mid-latitudes (30°S-60°S)\n",
    "izon = 1\n",
    "da_famean_latzone[:, :, izon].plot(figsize=(12, 4), x='time', y='alt',\n",
    "                                   xlim=[date_from, date_to], ylim=[0.0, 12.0],\n",
    "                                   vmin=-100.0, vmax=100.0, extend='max', cmap='RdBu_r',\n",
    "                                   cbar_kwargs={'label': \"Humidity anomaly  [%]\"})\n",
    "plt.title('Southern mid-latitudes: 30°S-60°S', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Altitude  [km]')\n",
    "plt.xlabel('')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find that the seasonal variation of humidity is stronger at northern mid-latitudes than at southern mid-latitudes, while they are almost absent at low latitudes.\n",
    "\n",
    "\n",
    "#### 4.3.3 Averaging humidity anomalies in vertical layers\n",
    "\n",
    "Specific humidity normally falls off rapidly with height. This is also the case for anomalies, while the fractional anomalies do not exhibit any underlying strong height dependence. We will now average the fractional anomalies in 4 kilometer thick vertical layers (0-4 km, 4-8 km, and 8-12 km) allowing us to do line plotting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary defining the vertical layers\n",
    "layers = {\n",
    "    '0-4km':  [0,  0, 20],   # {'bounds': [0,4000],     'colour': '#ca313e'},\n",
    "    '4-8km':  [1, 20, 40],   # {'bounds': [4000,8000],  'colour': '#eace24'},\n",
    "    '8-12km': [2, 40, 60]}   # {'bounds': [8000,12000], 'colour': '#428ed0'}}\n",
    "\n",
    "# Define a new data array to hold the layer averages of anomalies\n",
    "da_famean_latzone_layer = da_famean_latzone[:, 0:3, :].copy().rename({'alt': 'layer'})\n",
    "\n",
    "# Define a new Xarray data array to hold the layer averages of deseasonalized anomalies\n",
    "da_desfamean_latzone_layer = da_desfamean_latzone[:, 0:3, :].copy().rename({'alt': 'layer'})\n",
    "\n",
    "# Compute averages in three vertical layers\n",
    "for ilay in layers:\n",
    "    i = layers[ilay][0]\n",
    "    k = layers[ilay][1]\n",
    "    n = layers[ilay][2]\n",
    "    da_famean_latzone_layer[:, i, :] = da_famean_latzone[:, k:n, :].mean(dim='alt',\n",
    "                                                                         skipna=True)\n",
    "    da_desfamean_latzone_layer[:, i, :] = da_desfamean_latzone[:, k:n, :].mean(dim='alt',\n",
    "                                                                               skipna=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.4 Seasonal cycles in height layers\n",
    "\n",
    "We can now plot the vertically averaged fractional anomalies as time series. Let us again do this for three latitude zones: northern mid-latitudes, low latitudes, and southern mid-latitudes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start/end times as instances of cftime\n",
    "date_from = cftime.datetime(year=np_year[0], month=np_month[0],  day=16)\n",
    "date_to   = cftime.datetime(year=np_year[Ntime-1], month=np_month[Ntime-1], day=16)\n",
    "\n",
    "# Vertically averaged global-mean humidity anomalies, flip to get the 8-12 km layer first\n",
    "izon = 3   # 30°N-60°N\n",
    "da_hum_nmid = da_famean_latzone_layer[:, :, izon].squeeze()\n",
    "da_hum_nmid = np.flip(da_hum_nmid)\n",
    "izon = 2   # 30°S-30°N\n",
    "da_hum_low = da_famean_latzone_layer[:, :, izon].squeeze()\n",
    "da_hum_low = np.flip(da_hum_low)\n",
    "izon = 1   # 30°S-60°S\n",
    "da_hum_smid = da_famean_latzone_layer[:, :, izon].squeeze()\n",
    "da_hum_smid = np.flip(da_hum_smid)\n",
    "\n",
    "# Define figure\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(3, 1, figsize=(12, 15))\n",
    "\n",
    "# Plot humidity, 30°N-60°N\n",
    "ax1.set_prop_cycle(color=['#0334BB', 'green', '#CC0000'])\n",
    "da_hum_nmid[:, 0:3].plot.line(ax=ax1, x='time', xlim=[date_from, date_to], ylim=[-75.0, 125.0],\n",
    "                              yticks=[-50, 0, 50, 100], linewidth=1.8, add_legend=True)\n",
    "ax1.legend(['8-12 km', '4-8 km', '0-4 km'], loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "ax1.set_title('Northern mid-latitudes: 30°N-60°N', fontsize=14, fontweight='bold')\n",
    "ax1.set_xlabel('')\n",
    "ax1.set_ylabel('Humidity anomaly  [%]')\n",
    "ax1.grid(which='major', axis='y')\n",
    "\n",
    "# Plot humidity, 30°S-30°N\n",
    "ax2.set_prop_cycle(color=['#0334BB', 'green', '#CC0000'])\n",
    "da_hum_low[:, 0:3].plot.line(ax=ax2, x='time', xlim=[date_from, date_to], ylim=[-75.0, 125.0],\n",
    "                             yticks=[-50, 0, 50, 100], linewidth=1.8, add_legend=True)\n",
    "ax2.legend(['8-12 km', '4-8 km', '0-4 km'], loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "ax2.set_title('Low latitudes: 30°S-30°N', fontsize=14, fontweight='bold')\n",
    "ax2.set_xlabel('')\n",
    "ax2.set_ylabel('Humidity anomaly  [%]')\n",
    "ax2.grid(which='major', axis='y')\n",
    "\n",
    "# Plot humidity, 30°S-60°S\n",
    "ax3.set_prop_cycle(color=['#0334BB', 'green', '#CC0000'])\n",
    "da_hum_smid[:, 0:3].plot.line(ax=ax3, x='time', xlim=[date_from, date_to], ylim=[-75.0, 125.0],\n",
    "                              yticks=[-50, 0, 50, 100], linewidth=1.8, add_legend=True)\n",
    "ax3.legend(['8-12 km', '4-8 km', '0-4 km'], loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "ax3.set_title('Southern mid-latitudes: 30°S-60°S', fontsize=14, fontweight='bold')\n",
    "ax3.set_xlabel('')\n",
    "ax3.set_ylabel('Humidity anomaly  [%]')\n",
    "ax3.grid(which='major', axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same picture emerges: the seasonal variation of humidity is stronger in the northern hemisphere than in the southern hemisphere, while they are almost absent at low latitudes.\n",
    "\n",
    "Let us now look at the global variation with season:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select global means (90°S-90°N)\n",
    "izon = 5\n",
    "\n",
    "# Vertically averaged global-mean humidity anomalies, flip to get the 8-12 km layer first\n",
    "da_hum = da_famean_latzone_layer[:, :, izon].squeeze()\n",
    "da_hum = np.flip(da_hum, 1)\n",
    "\n",
    "# Define figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4.4))\n",
    "\n",
    "# Plot humidity\n",
    "ax.set_prop_cycle(color=['#0334BB', 'green', '#CC0000'])\n",
    "da_hum[:, 0:3].plot.line(ax=ax, x='time', xlim=[date_from, date_to], ylim=[-30.0, 30.0],\n",
    "                         yticks=[-20, -10, 0, 10, 20], linewidth=1.8, add_legend=True)\n",
    "plt.legend(['8-12 km', '4-8 km', '0-4 km'], loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.title('Global: 90°S-90°N', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Humidity anomaly / %')\n",
    "plt.grid(which='major', axis='y')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a seasonal variation also in global data, dominated by the northern hemisphere seasons. Let us now see which humidity variations that remain if we plot the de-seasonalized anomalies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select global means (90°S-90°N)\n",
    "izon = 5\n",
    "\n",
    "# Vertically averaged global-mean humidity anomalies, flip to get the 8-12 km layer first\n",
    "da_hum = da_desfamean_latzone_layer[:, :, izon].squeeze()\n",
    "da_hum = np.flip(da_hum, 1)\n",
    "\n",
    "# Define figure\n",
    "fig, ax = plt.subplots(1, 1, figsize=(12, 4.4))\n",
    "\n",
    "# Plot humidity\n",
    "ax.set_prop_cycle(color=['#0334BB', 'green', '#CC0000'])\n",
    "da_hum[:, 0:3].plot.line(ax=ax, x='time', xlim=[date_from, date_to], ylim=[-30.0, 30.0],\n",
    "                         yticks=[-20, -10, 0, 10, 20], linewidth=1.8, add_legend=True)\n",
    "plt.legend(['8-12 km', '4-8 km', '0-4 km'], loc='upper left', bbox_to_anchor=(1.0, 1.0))\n",
    "plt.title('Global: 90°S-90°N', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('')\n",
    "plt.ylabel('Humidity anomaly / %')\n",
    "plt.grid(which='major', axis='y')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We find a semi-annual variation in global humidity on the order of 5-10% on top of the mean seasonal variation. Several minima and maxima can be identified which coincide with different phases of the El Niño Southern Oscillation (ENSO) cycles. This is further explored in Use case 4 below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Use case 4:  Global humidity and the El Niño Southern Oscillation\n",
    "\n",
    "To proceed with this Use case you first need to go through Use case 3, as those time series are used here.\n",
    "\n",
    "The El Niño-Southern Oscillation (ENSO) is a recurring phenomenon in the central and eastern tropical Pacific Ocean. On periods ranging from about three to seven years, the surface waters across a large swath of the tropical Pacific Ocean warm or cool by anywhere from 1°C to 3°C, compared to normal. The phase of the ENSO cycle is commonly quantified by indices describing the sea-surface temperatures (SSTs) in central parts of the Pacific, e.g., the NINO 3.4 index which can be thought of as the equatorial SSTs averaged from the dateline to the South American coast (5°S-5°N, 120°W-170°W).\n",
    "\n",
    "The NINO 3.4 index is generated and distributed by NOAA's Climate Prediction Center (https://www.cpc.ncep.noaa.gov).\n",
    "Let us download the file https://www.cpc.ncep.noaa.gov/data/indices/oni.ascii.txt, extract monthly data for the duration of the humidity time series, and store that data as a Numpy array. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the ENSO data file from NOAA's Climate Prediction Center\n",
    "url = 'https://www.cpc.ncep.noaa.gov/data/indices/oni.ascii.txt'\n",
    "ensofile = DATADIR + 'enso.dat'\n",
    "urlretrieve(url, ensofile)\n",
    "\n",
    "# List the seasons used in the ENSO data file\n",
    "seastrng = ['DJF', 'JFM', 'FMA', 'MAJ', 'AMJ', 'MJJ',\n",
    "            'JJA', 'JAS', 'ASO', 'SON', 'OND', 'NDJ']\n",
    "\n",
    "# Read data from the file\n",
    "f = open(ensofile, 'r')\n",
    "seas_enso = np.genfromtxt(f, dtype=str,   skip_header=1, usecols=(0))\n",
    "f.seek(0)\n",
    "year_enso = np.genfromtxt(f, dtype=int,   skip_header=1, usecols=(1))\n",
    "f.seek(0)\n",
    "data_enso = np.genfromtxt(f, dtype=float, skip_header=1, usecols=(2, 3))\n",
    "f.close()\n",
    "\n",
    "# Locate the month in the ENSO record that coincide with the start the humidity data record\n",
    "i0 = -1\n",
    "for i in range(len(year_enso)):\n",
    "    if year_enso[i] == year0 and seas_enso[i] == seastrng[month0-1]:\n",
    "        i0 = i\n",
    "\n",
    "# The ENSO 3.4 index during the humidity data record\n",
    "mean_enso = data_enso[i0:i0+Ntime, 0].squeeze()\n",
    "anom_enso = data_enso[i0:i0+Ntime, 1].squeeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select global mean humidity anomalies from Use case 3. Use the de-seasonalized anomalies of data vertically averaged in latitude zones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select global means (90°S-90°N)\n",
    "izon = 5\n",
    "\n",
    "# Vertically averaged global-mean humidity anomalies, flip to get the 8-12 km layer first\n",
    "da_hum = da_desfamean_latzone_layer[:, :, izon].squeeze()\n",
    "da_hum = np.flip(da_hum, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now plot the ENSO data along with the global humidity anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate positive-only and negative-only ENSO time series\n",
    "x = np.arange(Ntime)\n",
    "yzero = np.zeros(Ntime)\n",
    "ypos = np.where(anom_enso >= 0.0, anom_enso, yzero)\n",
    "yneg = np.where(anom_enso < 0.0,  anom_enso, yzero)\n",
    "\n",
    "# Define figure\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "\n",
    "# Plot global humidity\n",
    "ax1.set_prop_cycle(color=['#0334BB', 'green', '#CC0000'])\n",
    "ax1.plot(x, da_hum[:, 0:3], linewidth=1.8)\n",
    "ax1.set_xlim(xmin=0, xmax=Ntime)\n",
    "ax1.set_ylim(ymin=-15.0, ymax=20.0)\n",
    "ax1.set_yticks([-15, -10, -5, 0, 5, 10, 15, 20])\n",
    "ax1.grid(which='major')\n",
    "ax1.legend(['8-12 km', '4-8 km', '0-4 km'])\n",
    "ax1.set_ylabel('Humidity  [%]')\n",
    "ax1.set_title('Global humidity anomaly', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Plot ENSO\n",
    "ax2.plot(x, anom_enso, 'black', linewidth=1.6)\n",
    "ax2.set_xlim(xmin=0, xmax=Ntime)\n",
    "ax2.set_ylim(ymin=-2.55, ymax=3.4)\n",
    "ax2.set_yticks([-2.55, -1.70, -0.85, 0.0, 0.85, 1.70, 2.55, 3.40])\n",
    "ax2.grid(which='major')\n",
    "ax2.fill_between(x, ypos, color='#CC0000')\n",
    "ax2.fill_between(x, yneg, color='#0334BB')\n",
    "ax2.set_ylabel('NINO 3.4  [K]')\n",
    "ax2.set_title('ENSO index', fontsize=14, fontweight='bold')\n",
    "\n",
    "# Save the figure\n",
    "# fig.savefig(f'{DATADIR}ERA5_global_2016_anomaly_eur.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a close correspondence between the phase of ENSO and global humidity anomalies, where the humidity seems to lag ENSO by about 2-4 months. It appears that the ENSO is a major governing factor for global humidity. The details of the causality, e.g., which parts of the globe that contribute to this relation and what the relevant correlations and time lags are, is something that could be further studied with this and other humidity datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 5. References\n",
    "\n",
    "Gleisner, H., K.B. Lauritsen, J.K. Nielsen, and S. Syndergaard, (2020): Evaluation of the 15-year ROM SAF monthly mean GPS radio occultation climate data record, Atmos. Meas. Tech., 13, 3081–3098, DOI: https://doi.org/10.5194/amt-13-3081-2020\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
