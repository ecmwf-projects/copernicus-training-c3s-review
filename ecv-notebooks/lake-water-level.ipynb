{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e32bf775",
   "metadata": {},
   "source": [
    "# Tutorial: Visualising Lake Water Level (LWL) timeseries\n",
    "\n",
    "<font color='red'>Before continuing with this tutorial, please verify that the C3S API is installed. All the information about this api is available at: </font>\n",
    "\n",
    "https://cds.climate.copernicus.eu/api-how-to#install-the-cds-api-key\n",
    "\n",
    "\n",
    "****\n",
    "\n",
    "In this tutorial we will access lake products from the Climate Data Store (CDS) and analyse the timeseries of the lake water level on a selected lake. The tutorial comprises two main steps:\n",
    "\n",
    "1. Dowload and decompress data \n",
    "2. Visualise the location of the lake in a map\n",
    "3. Visualise and save water level timeseries\n",
    "4. Visualise and save the yearly water level anomalies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d0c53a5",
   "metadata": {},
   "source": [
    "## Import librairies\n",
    "\n",
    "\n",
    "The lake water level data will be download in a zip file containing a NetCDF file. We need libraries to download data from the CDS but also libraires to manage zip files (zipfile library) and  NetCDF files (xarray library). We also use libraries to plot and visualise data (matplotlib and cartopy libraries).\n",
    "\n",
    "Additional libraires: os and glob are used for file management "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c43d1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import os\n",
    "import glob\n",
    "import zipfile\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from cartopy import crs, feature\n",
    "\n",
    "%matplotlib widget\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cc445f",
   "metadata": {},
   "source": [
    "Current version of the Lake Water Level dataset in CDS (v2.1) contains timeseries from 94 lakes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8111a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_lakes = ['amadjuak', 'argentino', 'athabasca', 'ayakkum', 'aylmer', 'baikal','baker', 'balbina', \n",
    "                   'balkhash', 'beysehir', 'bosten', 'bratskoye','cahora_bassa', 'caribou', 'caspian', 'cedar', \n",
    "                   'chardarya', 'dagze_co','des_bois', 'dogaicoring_q', 'dubawnt','erie', 'fort_peck', \n",
    "                   'grande_trois','greatslave', 'guri', 'har','hongze', 'hovsgol', 'hulun','huron', 'issykkul', \n",
    "                   'kainji','kapchagayskoye', 'kara_bogaz_gol', 'kariba','kasba', 'khanka', 'kokonor',\n",
    "                   'krasnoyarskoye', 'kremenchutska', 'kuybyshevskoye','kyoga', 'ladoga', 'lagoa_dos_patos', \n",
    "                   'langa_co', 'lixiodain_co', 'malawi','manitoba', 'michigan', 'migriggyangzham', 'mossoul', \n",
    "                   'mweru', 'namco', 'nasser', 'ngangze', 'ngoring_co', 'nicaragua', 'novosibirskoye', \n",
    "                   'nueltin','onega', 'ontario', 'opinac','peipus', 'rukwa', 'rybinskoye', 'saint_jean', \n",
    "                   'sakakawea', 'saksak','saratovskoye', 'sarykamish', 'sasykkol','soungari', 'superior', \n",
    "                   'tana','tanganika', 'tangra_yumco', 'tchad','tchany', 'tharthar', 'todos_los_santos',\n",
    "                   'tsimlyanskoye', 'turkana', 'ulungur','vanerm', 'victoria', 'volta','williston', \n",
    "                   'winnipeg', 'winnipegosis','yellowstone', 'zeyskoye', 'zhari_namco','ziling']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9fa756",
   "metadata": {},
   "source": [
    "# Lake selection\n",
    "\n",
    "\n",
    "For downloading and generating the timeserie, two inputs are required:\n",
    "\n",
    "- The name of the lake (lake_name). The name of the lake must exists in the list of available lakes\n",
    "- The output directory name(output_dir) where the different files will be save."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86013549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the name of the lake\n",
    "lake_name = \"Baikal\"\n",
    "\n",
    "# the output directory name \n",
    "output_dir = 'output'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb03e7e",
   "metadata": {},
   "source": [
    "A test is performed to verify that the water level for the selected lake is available "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6fcf6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if lake_name.lower() not in available_lakes :\n",
    "    print (f'The lake \"{lake_name}\" is not still available')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d512b10",
   "metadata": {},
   "source": [
    "The output directory must exitst. If it is not the case, it must be created. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31d7e4fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(output_dir) == False:\n",
    "    print (f'The output dir \"{output_dir}\" does not exist. You need to create before continue')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f180c8",
   "metadata": {},
   "source": [
    "## 1. Dowload and decompress data\n",
    "\n",
    "Having the CDS api, this function will retrive the  data for the selected lake into the defined output directory. The downloaded file is compressed (zip format) containing the data file in NetCDF format. For reading the lake water level data, the file will be extracted in the output directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e830d1cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method lower of str object at 0x7fc1c0f8bcf0>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-13 11:10:08,598 INFO Welcome to the CDS\n",
      "2023-07-13 11:10:08,598 INFO Sending request to https://cds.climate.copernicus.eu/api/v2/resources/satellite-lake-water-level\n",
      "2023-07-13 11:10:08,671 INFO Request is completed\n",
      "2023-07-13 11:10:08,672 INFO Downloading https://download-0013-clone.copernicus-climate.eu/cache-compute-0013/cache/data2/dataset-satellite-lake-water-level-2266e468-00ea-4829-82d3-37cd29e7a436.zip to output/Baikal.zip (17.2K)\n",
      "2023-07-13 11:10:08,912 INFO Download rate 72K/s\n"
     ]
    }
   ],
   "source": [
    "print (lake_name.lower)\n",
    "c = cdsapi.Client()\n",
    "c.retrieve( 'satellite-lake-water-level',\n",
    "            {\n",
    "                'lake': [lake_name.lower()],\n",
    "                'variable': 'water_surface_height',\n",
    "                'format': 'zip' # valid formats: zip, tar and tgz\n",
    "            },\n",
    "           f'{output_dir}/{lake_name}.zip'\n",
    "           )\n",
    "\n",
    "with zipfile.ZipFile(f'{output_dir}/{lake_name}.zip') as z:\n",
    "    z.extractall(f'{output_dir}')\n",
    "    \n",
    "# recover the lake filename in netcdf format\n",
    "nc_file = glob.glob(f'{output_dir}/*{lake_name.upper()}*.nc')[0]\n",
    "\n",
    "# open the file with Xarray\n",
    "xr_lake = xr.open_dataset(nc_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f069d5",
   "metadata": {},
   "source": [
    " # 2. Visualise lake location\n",
    " \n",
    "It is always a useful idea to check the lake's location on a map. Many of the world's lakes have the same name but may be located in different countries, as in the case of Lake Victoria: the best known is in Uganda, but there is also a Lake Victoria in Canada (48.35N, 57.11W) and another in Australia (34.04S, 141.28E). Or the name of the lake is different, depending on the language: Caribou Lake or Rendeer lake refer to the same lake (Canada). In some cases, even with the same language, lake name can differ between countries: Lake Buenos Aires in Argentina and Lake General Carrera in Chili.\n",
    "\n",
    "\n",
    "A world map, with the location of the lake is displayed. For generating this figure we use the cartopy library. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "271f0398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29a2a68832ad434097221ecbabab6deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lake location (lat, lon): 53.58°, 108.17°\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fc1a0f3d1f0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig = plt.figure(figsize = (12,6))\n",
    "ax = plt.subplot(1,1,1, projection = crs.PlateCarree())\n",
    "\n",
    "ax.coastlines()\n",
    "ax.add_feature(feature.BORDERS, linewidth=0.5, edgecolor='blue')\n",
    "ax.stock_img()\n",
    "\n",
    "# add lake location \n",
    "lat = float(xr_lake.lake_barycentre_latitude.split()[0])\n",
    "if 'S' in xr_lake.lake_barycentre_latitude:\n",
    "    lat = -lat\n",
    "lon = float(xr_lake.lake_barycentre_longitude.split()[0])\n",
    "if 'W' in xr_lake.lake_barycentre_longitude:\n",
    "    lon = -lon\n",
    "    \n",
    "print (f\"Lake location (lat, lon): {lat}°, {lon}°\")\n",
    "plt.scatter(x = [lon], y = [lat], s = 30, color = 'red', transform = crs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c49d14",
   "metadata": {},
   "source": [
    " # 3. Visualise lake water level time series\n",
    "\n",
    "Now that the data has been extracted, we can read it and plot it. To read the data in NetCDF format we use the Xarray library and for the visualisation of the time series we use Matplotlib\n",
    "\n",
    "The figure with the timeseries will be saved in the output directory in png format:\n",
    "[lake_name]_timeseries.png file\n",
    "\n",
    "The change in time step due to coverage by multiple missions can be seen in the figure: in recent years, Lake Baikal has been monitored by multiple missions and trajectories. As a result, the temporal resolution increases (the time between observations is reduced) and the time series is noisier due to the effect of the inter-mission and inter-tracks bias. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97103012",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8906559cf98f4ec4bffe639e8a810de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot and visualise the timeseries\n",
    "fig = plt.figure(figsize = (12, 6))\n",
    "xr_lake.water_surface_height_above_reference_datum.plot()\n",
    "plt.title(f'Lake: {lake_name.title()}')\n",
    "\n",
    "# save the figure\n",
    "png_file = f'{output_dir}/{lake_name}_timeseries.png'\n",
    "plt.savefig(png_file, dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7e48b6",
   "metadata": {},
   "source": [
    " # 3. Visualise lake water level yearly anomalies\n",
    " \n",
    "Another way of analysing variations in water levels is to visualise anomalies in relation to average values over a reference period in the form of a bar chart, using red and blue colours to easily identify the year when levels are higher or lower than the climatic normal.\n",
    "\n",
    "The same code can be used for the visualiation of yearly anomalies compared to a particular year. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d69796fc",
   "metadata": {},
   "source": [
    "The reference period can be adapted to each lake. Indeed, the temporal coverage is not the same for all the lakes in the CDS, with the first available date ranging from 1992, as is the case for Lake Baikal, to 2019 for lakes monitored exclusively by the Sentinel-3B mission. In this example for Lake Baikal, we have chosen a reference period consisting of the first 10 years of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0d0446d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_reference_year = 1992\n",
    "last_reference_year  = 2002"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce619e70",
   "metadata": {},
   "source": [
    "The yearly anomaly is calculated by first applying xarray's groupby() function to group the data by year and then calculating the mean value for each annual group. The average value of the water in the reference lake is estimated as the average water level over the reference period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7949bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean LWL value during the reference period: 455.386 (m)\n"
     ]
    }
   ],
   "source": [
    "yearly_mean = xr_lake.groupby('time.year').mean(keep_attrs = True)\n",
    "\n",
    "ref = yearly_mean.where((yearly_mean.year >= first_reference_year ) & (yearly_mean.year <= last_reference_year ))\n",
    "ref_lwl_mean = np.nanmean(ref.water_surface_height_above_reference_datum.values)\n",
    "\n",
    "print (f'Mean LWL value during the reference period: {np.round(ref_lwl_mean,3)} (m)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe7cf4e",
   "metadata": {},
   "source": [
    "The yearly anomaly is shown in red for values above the average water level during the reference period and in blue for values below.\n",
    "\n",
    "The figure with the anomalies is saved in the output directory in png format :\n",
    "[lake_name]_yearly-anomalies.png file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "69a1ccde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "056ce74bcaff4306886cd61bf487167e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "year_mean = yearly_mean.to_dataframe()\n",
    "year_mean['lwl_yearly_anomaly'] = year_mean['water_surface_height_above_reference_datum'] - ref_lwl_mean\n",
    "year_mean['positive_anomaly'] = year_mean['lwl_yearly_anomaly'] > 0\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "year_mean['lwl_yearly_anomaly'].plot(kind='bar', \n",
    "                                     color = year_mean.positive_anomaly.map ({True: 'red', False: 'blue'}),\n",
    "                                     xlabel = '\\nYear',\n",
    "                                     ylabel = 'Lake Water Level Anomaly (m)',\n",
    "                                     title = f'Yearly water level anomalies on Lake {lake_name.title()}\\n reference period:  {first_reference_year} - {last_reference_year}')\n",
    "\n",
    "ax.grid()\n",
    "\n",
    "# save the figure\n",
    "png_file = f'{output_dir}/{lake_name}_yearly-anomalies.png'\n",
    "plt.savefig(png_file, dpi=300, bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
