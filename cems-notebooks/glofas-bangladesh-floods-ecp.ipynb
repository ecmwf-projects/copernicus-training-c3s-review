{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](../img/LogoLine_horizon_C3S.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observing major flood events with GLOFAS\n",
    "\n",
    "## About\n",
    "\n",
    "This tutorial will demonstrate how to investigate a specific flood event using data from the GLObal Flood\n",
    "Awareness Service (GLOFAS). For this example we look at the flood events: **EXAMPLE_1 and EXAMPLE_2**,\n",
    "and present **SOMETHING_THAT_WE_PRESENT**\n",
    "\n",
    "The GLOFAS data is produced operationally by ECMWF for the Copernicus Emergency Management Service (CEMS).\n",
    "\n",
    "The tutorial will first show how to download the necessary data from the C3S Climate Data Store (CDS). \n",
    "It will then describe how to **DO THE FIRT THING, then DO SOME MORE THINGS, and finally DO THE LAST THING.**\n",
    "\n",
    "The steps and methods here serve as demonstrative examples and could be applied to other events and datasets,\n",
    "e.g. fire and heatwave events."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![logo](../img/climate_indices.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<style>\n",
    "td, th {\n",
    "   border: 1px solid white;\n",
    "   border-collapse: collapse;\n",
    "}\n",
    "</style>\n",
    "<table align=\"left\">\n",
    "  <tr>\n",
    "    <th>Run the tutorial via free cloud platforms: </th>\n",
    "    <th><a href=\"https://mybinder.org/v2/gh/ecmwf-projects/copernicus-training-c3s-review/review?labpath=glofas-bangladesh-floods.ipynb\">\n",
    "        <img src = \"https://mybinder.org/badge.svg\" alt = \"Binder\"></th>\n",
    "    <th><a href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ecmwf-projects/copernicus-training-c3s-review/blob/review/glofas-bangladesh-floods.ipynb\">\n",
    "        <img src = \"https://kaggle.com/static/images/open-in-kaggle.svg\" alt = \"Kaggle\"></th>\n",
    "    <th><a href=\"https://colab.research.google.com/github/ecmwf-projects/copernicus-training-c3s-review/blob/review/glofas-bangladesh-floods.ipynb\">\n",
    "        <img src = \"https://colab.research.google.com/assets/colab-badge.svg\" alt = \"Colab\"></th>\n",
    "  </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search, download and view data\n",
    "\n",
    "Before we begin we must prepare our environment. This includes installing the Application Programming Interface (API) of the CDS, and importing the various python libraries that we will need.\n",
    "\n",
    "### Install CDS API\n",
    "\n",
    "To install the CDS API, run the following command. We use an exclamation mark to pass the command to the shell (not to the Python interpreter)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip -q install cdsapi\n",
    "\n",
    "# Other requirements:\n",
    "!pip -q install cfgrib ecmwflibs\n",
    "!pip -q install xarray netcdf4\n",
    "!pip -q install matplotlib\n",
    "!pip -q install cartopy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries\n",
    "\n",
    "We will be working with data in NetCDF format. To best handle this data we will use libraries for working with multidimensional arrays, in particular Xarray. We will also need libraries for plotting and viewing data, in this case we will use Matplotlib and Cartopy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# CDS API\n",
    "import cdsapi\n",
    "\n",
    "# Libraries for working with multidimensional arrays\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# Libraries for plotting and visualising data\n",
    "import matplotlib.path as mpath\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "\n",
    "# Disable warnings for data download via API\n",
    "import urllib3 \n",
    "urllib3.disable_warnings()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Enter your CDS API key\n",
    "\n",
    "We will request data from the Climate Data Store (CDS) programmatically with the help of the CDS API. Let us make use of the option to manually set the CDS API credentials. First, you have to define two variables: `URL` and `KEY` which build together your CDS API key. The string of characters that make up your KEY include your personal User ID and CDS API key. To obtain these, first register or login to the CDS (http://cds.climate.copernicus.eu), then visit https://cds.climate.copernicus.eu/api-how-to and copy the string of characters listed after \"key:\". Replace the `#########` below with this string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://cds.climate.copernicus.eu/api/v2'\n",
    "KEY = '##################################'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we specify a data directory in which we will download our data and all output files that we will generate:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = './data_dir'\n",
    "os.makedirs(DATADIR, exist_ok=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Search for the river discharge data we want\n",
    "\n",
    "The historical GLOFAS data can be found in [CDS catalogue entry](https://cds.climate.copernicus.eu/cdsapp#!/dataset/cems-glofas-historical)\n",
    "\n",
    "We are going to look at the Bangladesh flood YYYY-MM-DD"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Having selected the dataset, we now need to specify what product type, variables, temporal and geographic coverage we are interested in. These can all be selected in the **\"Download data\"** tab. In this tab a form appears in which we will select the following parameters to download:\n",
    "\n",
    "- Origin: `UERRA-HARMONIE`\n",
    "- Variable: `10m wind speed` and `2m temperature` (these will need to be selected one at a time)\n",
    "- Year: `1989 to 2018`\n",
    "- Month: `January`\n",
    "- Day: `15`\n",
    "- Time: `06:00`\n",
    "- Format: `NetCDF`\n",
    "\n",
    "At the end of the download form, select **\"Show API request\"**. This will reveal a block of code, which you can simply copy and paste into a cell of your Jupyter Notebook (see cells below). You will do this twice: once for 10m wind speed and again for 2m temperature.\n",
    "\n",
    "#### Download data\n",
    "\n",
    "... having copied the API request into the cell below, running this will retrieve and download the data you requested into your local directory. However, before you run the cell below, the **terms and conditions** of this particular dataset need to have been accepted in the CDS. The option to view and accept these conditions is given at the end of the download form, just above the **\"Show API request\"** option."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Note:** NOTE ABOUT THE DATA ACCESS?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file = f\"{DATADIR}/download.grib\"\n",
    "if not os.path.isfile(download_file):\n",
    "    c = cdsapi.Client()\n",
    "    c.retrieve(\n",
    "        'cems-glofas-historical',\n",
    "        {\n",
    "            'system_version': 'version_4_0',\n",
    "            'hydrological_model': 'lisflood',\n",
    "            'product_type': 'consolidated',\n",
    "            'variable': 'river_discharge_in_the_last_24_hours',\n",
    "            'hyear': [f\"{year}\" for year in range(2012, 2023)],\n",
    "            'hmonth': 'june',\n",
    "            'hday': [f\"{day:02d}\" for day in range(1,31)],\n",
    "            'format': 'grib',\n",
    "            'area': [30, 85, 20, 95,],\n",
    "        },\n",
    "    ).download(download_file)\n",
    "glofas_data = xr.open_dataset(download_file)\n",
    "glofas_data.dis24.mean(dim='time').plot()\n",
    "glofas_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_area_file = f\"{DATADIR}/uparea_glofas_v4_0.nc\"\n",
    "u_version=2\n",
    "upstream_data_url = f\"https://confluence.ecmwf.int/download/attachments/242067380/{upstream_area_file}?version={u_version}&modificationDate=1668604690076&api=v2&download=true\"\n",
    "if not os.path.isfile(upstream_area_file):\n",
    "    os.system(f\"wget -q {upstream_data_url}\")\n",
    "    os.rename(f\"{upstream_area_file}?version={u_version}\", upstream_area_file)\n",
    "upstream_area = xr.open_dataset(upstream_area_file)\n",
    "upstream_area.uparea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce the Upstream area data to the domain of the river discharge\n",
    "\n",
    "# Get the latitude and longitude limits of the data\n",
    "lat_limits = [glofas_data.latitude.values[i] for i in [0, -1]]\n",
    "lon_limits = [glofas_data.longitude.values[i] for i in [0, -1]]\n",
    "# print(lat_limits)\n",
    "# print(lon_limits)\n",
    "up_lats = upstream_area.latitude.values.tolist()\n",
    "up_lons = upstream_area.longitude.values.tolist()\n",
    "\n",
    "lat_slice_index = [\n",
    "    round((i-up_lats[0])/(up_lats[1]-up_lats[0]))\n",
    "    for i in lat_limits\n",
    "]\n",
    "lon_slice_index = [\n",
    "    round((i-up_lons[0])/(up_lons[1]-up_lons[0]))\n",
    "    for i in lon_limits\n",
    "]\n",
    "# print(lat_slice_index, [up_lats[i] for i in lat_slice_index])\n",
    "# print(lon_slice_index, [up_lons[i] for i in lon_slice_index])\n",
    "\n",
    "# Slice upstream area to bangladesh region:\n",
    "red_upstream_area = upstream_area.isel(\n",
    "    latitude=slice(lat_slice_index[0], lat_slice_index[1]+1),\n",
    "    longitude=slice(lon_slice_index[0], lon_slice_index[1]+1),\n",
    ")\n",
    "# print('Check limits: ')\n",
    "# print(lat_limits, red_upstream_area.latitude.values[[0,-1]])\n",
    "print(lon_limits, red_upstream_area.longitude.values[[0,-1]])\n",
    "\n",
    "# There are very minor rounding differences, so we update with the lat/lons from the glofas data\n",
    "red_upstream_area = red_upstream_area.assign_coords({\n",
    "    'latitude': glofas_data.latitude,\n",
    "    'longitude': glofas_data.longitude,\n",
    "})\n",
    "glofas_data['uparea'] = red_upstream_area['uparea']\n",
    "glofas_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask data\n",
    "\n",
    "We now mask the data to where the upstream area is True??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Xarray Data Arrays\n",
    "# glofas_mean.dis24.plot()\n",
    "glofas_data_masked = glofas_data.where(glofas_data.uparea>1e10)\n",
    "glofas_data_masked\n",
    "glofas_data_masked.dis24.mean(dim='time').plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the `longitude` variables in the Xarray Dataset and Data Array objects are in the range of `[0, 359.75]`. Let us convert them into a `[-180, 180]` grid:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aw['longitude'] = ((aw.longitude + 180) % 360) - 180\n",
    "at['longitude'] = ((at.longitude + 180) % 360) - 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate wind chill index\n",
    "The wind chill index is a metric in temperature-like units, e.g. Kelvin or °C, and represents the lowering of body temperature due to a combination of low temperature and wind.\n",
    "\n",
    "Since 2001, Canada, the United States and the United Kingdom have implemented the new wind chill index which is defined with the following formula:\n",
    "\n",
    "$\\textit{T}_{WC} = 13.12 + 0.6215\\textit{T}_{a} - 11.37\\upsilon^{0.16} + 0.3965\\textit{T}_{a}\\upsilon^{0.16}$\n",
    "\n",
    "where:\n",
    "- $\\textit{T}_{WC}$ = wind chill index\n",
    "- $\\textit{T}_{a}$ = air temperature in degrees Celsius\n",
    "- $\\upsilon$ = wind speed at 10 m standard anemometer height, in kilometres per hour\n",
    "\n",
    "We will apply this formula on our data to calculate the wind chill index for a particular period of time over Europe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To calculate $\\textit{T}_{WC}$ we first have to ensure our data is in the right units. For the wind speed we need to convert from m/s to km/h, and for air temperature we need to convert from Kelvin to degrees Celsius:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wind speed, convert from m/s to km/h: si10 * 1000 / (60*60)\n",
    "w = aw * 3600 / 1000\n",
    "# air temperature, convert from Kelvin to Celsius: t2m - 273.15\n",
    "t = at - 273.15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can calculate the North American and United Kingdom wind chill index:\n",
    "$\\textit{T}_{WC} = 13.12 + 0.6215\\textit{T}_{a} - 11.37\\upsilon^{0.16} + 0.3965\\textit{T}_{a}\\upsilon^{0.16}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twc = 13.12 + (0.6215*t) - (11.37*(w**0.16)) + (0.3965*t*(w**0.16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's calculate the average wind chill for 06:00 on 15 January for the 30 year period from 1989 to 2018:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twc_mean = twc.mean(dim='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we plot the results, let's take the same European subset as that used for the [C3S Climate Bulletins](https://climate.copernicus.eu/climate-bulletins)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "twc_mean_sub = twc_mean.where((twc_mean.latitude < 72) & \n",
    "                              (twc_mean.latitude > 34) & \n",
    "                              (twc_mean.longitude < 40) & \n",
    "                              (twc_mean.longitude > -25), drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's plot the average wind chill for this time over Europe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 1, figsize = (18, 9), \n",
    "                       subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "im = plt.pcolormesh(twc_mean_sub.longitude, twc_mean_sub.latitude, twc_mean_sub, cmap='cool') \n",
    "\n",
    "ax.set_title('Wind Chill Index 12:00, 15 Jan, 1989 to 2018', fontsize=16)\n",
    "ax.gridlines(draw_labels=False, linewidth=1, color='gray', alpha=0.5, linestyle='--') \n",
    "ax.coastlines(color='black')\n",
    "ax.set_extent([-25, 40, 34, 72], crs=ccrs.PlateCarree())\n",
    "\n",
    "cbar = plt.colorbar(im,fraction=0.04, pad=0.01)\n",
    "cbar.set_label('Wind Chill Index') \n",
    "\n",
    "fig.savefig(f'{DATADIR}UERRA_wind_chill_index_midJan.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under which category of the wind chill index do the coldest areas in Europe generally lie at this time (see chart below)?\n",
    "\n",
    "![logo](./img/Windchill_effect_en.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RicHard-59, CC BY-SA 3.0 <https://creativecommons.org/licenses/by-sa/3.0>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise: Repeat process with ERA5 data and compare results\n",
    "\n",
    "So far you have plotted wind chill using the UERRA regional reanalysis dataset, but how accurate is this plot? One way to assess a dataset is to compare it with an alternative independent one to see what differences there may be. An alternative to UERRA is the ECMWF Reanalysis datasets, ERA5 (currently in it's 5th version). Repeat the steps above with ERA5 data and compare your results with those obtained using UERRA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "JUPYTER-DEVELOP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "58c7fce056d33f98990852c386399bc548e011ab130732c30e7ec3c06b4dec9d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
